{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQKY9-Qhn-2u"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets # Importando os Datasets necessários para o treinamento\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# O Torchvision é uma biblioteca que fornece várias ferramentas úteis para o processamento de imagens\n",
        "# incluindo conjuntos de dados populares para treinamento de modelos de visão computacional."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST é um dataset que contém várias imagens de números escritos à mão (de 0 a 9).\n",
        "dados_treinamento = datasets.MNIST( # Separando os dados para treinamento do Modelo\n",
        "    root = 'data', # Indica onde os dados serão armazenados\n",
        "    train = True, # Especifica que deve ser o conjunto de imagens de Treinamento\n",
        "    transform = ToTensor(), # Transforma as imagens em um conjunto numérico que é processável pelo Pytorch\n",
        "    download = True, # Indica que caso o dataset não exista no diretório, deve ser baixado.\n",
        ")\n",
        "\n",
        "dados_teste = datasets.MNIST( # Separando os Dados para Testar a acurácia do Modelo\n",
        "    root = 'data',\n",
        "    train = False, # Especifica que deve ser o conjunto de imagens de Teste\n",
        "    transform = ToTensor(),\n",
        "    download = True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWaVDFF-oc0j",
        "outputId": "8a12c378-6de7-4b8d-95fc-84f4570e6f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 22.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 599kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.76MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.13MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VERIFICANDO O DATASET DE TREINAMENTO\n",
        "print(dados_treinamento)\n",
        "\n",
        "# VERIFICANDO O TAMANHO DAS IMAGENS\n",
        "print(dados_treinamento.data.shape) # 28x28 = 784 pixels, ou no caso, informações de 0-1 (preto - branco)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRUUv9u4pTYx",
        "outputId": "51b514cc-e562-492f-8d2e-5f0d781d5ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "torch.Size([60000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VERIFICANDO O DATASET DE TESTES\n",
        "print(dados_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya_T1lffpYgp",
        "outputId": "9cc0fa19-0663-4d9a-e5b5-268939a6161a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a Função para carregar os dados no Modelo\n",
        "from torch.utils.data import DataLoader # O data Loader permite carregar os Dados no modelo em Lote, além de abstrair muitas configurações que de outro modo seriam manuais\n",
        "\n",
        "loaders = { # Configurando os Loaders que vão carregar os Dados\n",
        "    # Loader de Dados de Treinamento\n",
        "    'treinamento': DataLoader(dados_treinamento, # De onde ele deve retirar os dados\n",
        "                              batch_size=100, # O tamanho do Lote que será enviado para treinamento por iteração\n",
        "                              shuffle=True, # Permite o Embaralhamento dos dados antes de enviar ao modelo (Evita que o modelo aprenda a ordem dos dados)\n",
        "                              num_workers=1,), # Quantidade de Threads\n",
        "    # Loader de Dados de Testagem\n",
        "    'teste': DataLoader(dados_teste,\n",
        "                              batch_size=100,\n",
        "                              shuffle=True,\n",
        "                              num_workers=1,),\n",
        "}"
      ],
      "metadata": {
        "id": "_2D26-5zp2Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFININDO O MODELO E ARQUITETURA DA REDE NEURAL\n",
        "import torch.nn as nn # Módulos e as funções para criar redes neurais. | nn = Neural Network\n",
        "import torch.nn.functional as F # Funções de ativação, operações de pooling, etc. Essenciais para treinar os Modelos\n",
        "import torch.optim as optim # Biblioteca para otimizadores, que ajudam a ajustar os parâmetros da rede durante o treinamento.\n",
        "\n",
        "class Modelo(nn.Module):\n",
        "  # Método Construtor da Classe\n",
        "  def __init__(self):\n",
        "    super(Modelo,self).__init__() # Estamos chamando o hama o construtor da classe base nn.Module para que a nossa classe Modelo tenha suas funcionalidades.\n",
        "\n",
        "    # Definindo as camadas da rede neural (Arquitetura)\n",
        "      ```\n",
        "      Breve Explicação\n",
        "        1. As camadas convolucionais recebem dados estruturados em grades\n",
        "        elas são responváveis por extrair caracteristicas das imagens,\n",
        "        elas detectam padrões e elas não analisam toda a imagem de uma vez,\n",
        "        mas por partes, por pequenas regiões da imagem.\n",
        "      ```\n",
        "\n",
        "    self.conv_layer1 = nn.Conv2d(1,10,kernel_size=5) # 1 = Um canal de entrada, apenas pois é escala de cinza | 10 = Aplicaremos 10 filtros para tentar encontrar 10 mapas de Caracteristicas.\n",
        "    self.conv_layer2 = nn.Conv2d(10,20,kernel_size=5) # 10 = Justamente os 10 mapas de caracteristicas buscadas anteriormente | 20 = 20 filtros em cima das 10 entradas que chegaram da primeira camada\n",
        "    # Kernel_size = 5, significa que vamos olhar em regiões de 5x5 para cada imagem e realizar a operação de Convolução nela\n",
        "\n",
        "    self.conv_layer_drop = nn.Dropout2d() # Desligar aleatoriamente algumas conexões da rede durante o treinamento para evitar Overfitting, ao impedir que o modelo dependa demais de um mapa de caracteristica\n",
        "    self.fc1 = nn.Linear(320,50) # dense layer in tense flow\n",
        "    self.fc2 = nn.Linear(50,10)\n",
        "\n",
        "     ```\n",
        "      Breve Explicação 2\n",
        "        1. Essa rede em questão tem 2 Camadas Convolucionais, 1 Camada de Regularização (Dropout)\n",
        "        e 2 camadas 'fully conected', nessa sequência\n",
        "      ```\n",
        "\n",
        "  def forward(self, x):\n",
        "    # X = Dados\n",
        "    # Tensor = Array Multidimensional de Dados Numéricos Otimizado para Processamento em GPU\n",
        "    x = F.relu(F.max_pool2d(self.conv_layer1(x), 2)) # A função de Pooling vai olhar o mapa de Caracteristicas e Pegar o maior. (há outros tipos)\n",
        "    x = F.relu(F.max_pool2d(self.conv_layer_drop(self.conv_layer2(x)), 2)) # Aplicamos os dados na camada 2 -> Aplicamos o Dropout na Saida dos Dados -> Aplicamos outro Pooling antes de enviar para a próxima camada\n",
        "    x = x.view(-1, 320) # Transforma os valores de saida da ultima camada (Tensor 3D) e tranforma em um vetor númerico que pode ser processado pelas camadas \"Fully Connecteds\"\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training = self.training) # Aplica o Dropout apenas no treinamento\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return F.softmax(x) # Transforma as saidas do modelo em probabiblidades de 0 -1"
      ],
      "metadata": {
        "id": "oiVQyYXarHaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#  Se uma GPU com CUDA Cores estiver disponível, usar para acelerar processamento\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Modelo().to(device) # Carregar o modelo no dispositivo disponivel\n",
        "\n",
        "# Lr = Learning Rate\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Utiliza o Algoritmo ADAM para atualizar os pesos durante treinamento\n",
        "# Aqui dizemos ao otimizador para trabalhar em cima dos parametros do modelo\n",
        "# Lr é a taxa de aprendizado e controla o \"tamanho\" dos ajustes feitos nos pesos se for muito alta causará instabilidade\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss() # função que calcula a diferença entre a previsão do modelo e o resultado esperado\n",
        "\n",
        "\n",
        "# Definindo as Funções de Treinamento e Teste\n",
        "def train(epoch): # Função para treinar o Modelo\n",
        "  model.train() # Coloca o modelo em modo de Treinamento\n",
        "  # Iteração pelos Batchs de Dados de 100 em 100 usando o Loader de Treinamento\n",
        "  for batch_idx, (data,target) in enumerate(loaders['treinamento']): # Batch_idx = Index do Batch atual | Data = A imagem enviada | Target = A previsão Correta/esperada\n",
        "    data,target = data.to(device), target.to(device) # CPU ou GPU\n",
        "    optimizer.zero_grad() # Zerando os Gradientes, pois o Pytorch faz isso automáticamente | Gradientes = os valores que indicam como os parâmetros do modelo devem ser ajustados\n",
        "    output = model(data) # Predição feita\n",
        "    loss = loss_function(output,target) # Comparar com o resultado correto e calcular o erro\n",
        "    loss.backward() # Backpropagation - Calcular os Gradientes\n",
        "    optimizer.step() # Atualizar Parametros do Modelo\n",
        "    # Função para Controlar verificar o Progresso (A cada 20 Lotes - 2000 itens)\n",
        "    if batch_idx % 20 == 0:\n",
        "      print(f\"Epoch de Treinamento : {epoch} [{batch_idx * len(data)} / {len(loaders['treinamento'].dataset)}] ({100. * batch_idx /len(loaders['treinamento']):.0f}%) \\t % de Erro {loss.item():.6f}\")\n",
        "\n",
        "\n",
        "def test():\n",
        "  model.eval() # Coloca o modelo em modo de Avaliação\n",
        "  test_loss = 0 # Variável para acumular o valor da perda em todas as amostras do conjunto de teste.\n",
        "  correct = 0 # Contador de quantas previsões o modelo acertou.\n",
        "\n",
        "  with torch.no_grad(): #  desativa o cálculo de gradientes\n",
        "    for data, target in loaders['teste']: # Carrega os Dados de teste\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data) # Recebe a Saida\n",
        "      test_loss += loss_function(output,target).item() # Somar ao Valor de Perda\n",
        "      prediction = output.argmax(dim = 1,keepdim = True) # Receber o Valor Previsto pelo modelo\n",
        "      correct += prediction.eq(target.view_as(prediction)).sum().item() # Analisar se está correto\n",
        "\n",
        "  test_loss /= len(loaders['teste'].dataset) # Calcular a média de Perda\n",
        "  print(f\"Set de Teste: Perda Média{test_loss:.4f}: , Acurácia: {correct}/{len(loaders['teste'].dataset)} ({100. * correct / len(loaders['teste'].dataset):.0f}%\\n)\")\n"
      ],
      "metadata": {
        "id": "RDg7z8ZSt8D0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Começando o Treinamento\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN_h7Q3yysrU",
        "outputId": "10bc61f7-0584-4c06-b019-7b97d1cdc96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-f0309ddd8361>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch de Treinamento : 1 [0 / 60000] (0%) \t 2.302440\n",
            "Epoch de Treinamento : 1 [2000 / 60000] (3%) \t 2.287389\n",
            "Epoch de Treinamento : 1 [4000 / 60000] (7%) \t 2.113532\n",
            "Epoch de Treinamento : 1 [6000 / 60000] (10%) \t 2.037616\n",
            "Epoch de Treinamento : 1 [8000 / 60000] (13%) \t 1.894850\n",
            "Epoch de Treinamento : 1 [10000 / 60000] (17%) \t 1.855364\n",
            "Epoch de Treinamento : 1 [12000 / 60000] (20%) \t 1.806999\n",
            "Epoch de Treinamento : 1 [14000 / 60000] (23%) \t 1.799281\n",
            "Epoch de Treinamento : 1 [16000 / 60000] (27%) \t 1.757761\n",
            "Epoch de Treinamento : 1 [18000 / 60000] (30%) \t 1.685510\n",
            "Epoch de Treinamento : 1 [20000 / 60000] (33%) \t 1.787552\n",
            "Epoch de Treinamento : 1 [22000 / 60000] (37%) \t 1.710891\n",
            "Epoch de Treinamento : 1 [24000 / 60000] (40%) \t 1.721472\n",
            "Epoch de Treinamento : 1 [26000 / 60000] (43%) \t 1.689368\n",
            "Epoch de Treinamento : 1 [28000 / 60000] (47%) \t 1.749052\n",
            "Epoch de Treinamento : 1 [30000 / 60000] (50%) \t 1.705188\n",
            "Epoch de Treinamento : 1 [32000 / 60000] (53%) \t 1.653194\n",
            "Epoch de Treinamento : 1 [34000 / 60000] (57%) \t 1.719037\n",
            "Epoch de Treinamento : 1 [36000 / 60000] (60%) \t 1.647422\n",
            "Epoch de Treinamento : 1 [38000 / 60000] (63%) \t 1.641538\n",
            "Epoch de Treinamento : 1 [40000 / 60000] (67%) \t 1.701285\n",
            "Epoch de Treinamento : 1 [42000 / 60000] (70%) \t 1.703233\n",
            "Epoch de Treinamento : 1 [44000 / 60000] (73%) \t 1.679674\n",
            "Epoch de Treinamento : 1 [46000 / 60000] (77%) \t 1.732003\n",
            "Epoch de Treinamento : 1 [48000 / 60000] (80%) \t 1.612922\n",
            "Epoch de Treinamento : 1 [50000 / 60000] (83%) \t 1.622874\n",
            "Epoch de Treinamento : 1 [52000 / 60000] (87%) \t 1.619787\n",
            "Epoch de Treinamento : 1 [54000 / 60000] (90%) \t 1.621336\n",
            "Epoch de Treinamento : 1 [56000 / 60000] (93%) \t 1.609809\n",
            "Epoch de Treinamento : 1 [58000 / 60000] (97%) \t 1.640650\n",
            "Set de Teste: Perda Média0.0154: , Acurácia: 9270/10000 (93%\n",
            ")\n",
            "Epoch de Treinamento : 2 [0 / 60000] (0%) \t 1.583192\n",
            "Epoch de Treinamento : 2 [2000 / 60000] (3%) \t 1.632812\n",
            "Epoch de Treinamento : 2 [4000 / 60000] (7%) \t 1.601341\n",
            "Epoch de Treinamento : 2 [6000 / 60000] (10%) \t 1.643173\n",
            "Epoch de Treinamento : 2 [8000 / 60000] (13%) \t 1.547230\n",
            "Epoch de Treinamento : 2 [10000 / 60000] (17%) \t 1.610739\n",
            "Epoch de Treinamento : 2 [12000 / 60000] (20%) \t 1.687323\n",
            "Epoch de Treinamento : 2 [14000 / 60000] (23%) \t 1.592600\n",
            "Epoch de Treinamento : 2 [16000 / 60000] (27%) \t 1.711949\n",
            "Epoch de Treinamento : 2 [18000 / 60000] (30%) \t 1.630942\n",
            "Epoch de Treinamento : 2 [20000 / 60000] (33%) \t 1.602668\n",
            "Epoch de Treinamento : 2 [22000 / 60000] (37%) \t 1.542889\n",
            "Epoch de Treinamento : 2 [24000 / 60000] (40%) \t 1.584439\n",
            "Epoch de Treinamento : 2 [26000 / 60000] (43%) \t 1.554291\n",
            "Epoch de Treinamento : 2 [28000 / 60000] (47%) \t 1.585673\n",
            "Epoch de Treinamento : 2 [30000 / 60000] (50%) \t 1.568349\n",
            "Epoch de Treinamento : 2 [32000 / 60000] (53%) \t 1.553565\n",
            "Epoch de Treinamento : 2 [34000 / 60000] (57%) \t 1.587378\n",
            "Epoch de Treinamento : 2 [36000 / 60000] (60%) \t 1.598159\n",
            "Epoch de Treinamento : 2 [38000 / 60000] (63%) \t 1.602561\n",
            "Epoch de Treinamento : 2 [40000 / 60000] (67%) \t 1.617966\n",
            "Epoch de Treinamento : 2 [42000 / 60000] (70%) \t 1.561483\n",
            "Epoch de Treinamento : 2 [44000 / 60000] (73%) \t 1.533767\n",
            "Epoch de Treinamento : 2 [46000 / 60000] (77%) \t 1.538007\n",
            "Epoch de Treinamento : 2 [48000 / 60000] (80%) \t 1.589968\n",
            "Epoch de Treinamento : 2 [50000 / 60000] (83%) \t 1.590742\n",
            "Epoch de Treinamento : 2 [52000 / 60000] (87%) \t 1.583312\n",
            "Epoch de Treinamento : 2 [54000 / 60000] (90%) \t 1.535623\n",
            "Epoch de Treinamento : 2 [56000 / 60000] (93%) \t 1.573803\n",
            "Epoch de Treinamento : 2 [58000 / 60000] (97%) \t 1.573245\n",
            "Set de Teste: Perda Média0.0152: , Acurácia: 9466/10000 (95%\n",
            ")\n",
            "Epoch de Treinamento : 3 [0 / 60000] (0%) \t 1.609980\n",
            "Epoch de Treinamento : 3 [2000 / 60000] (3%) \t 1.550127\n",
            "Epoch de Treinamento : 3 [4000 / 60000] (7%) \t 1.593309\n",
            "Epoch de Treinamento : 3 [6000 / 60000] (10%) \t 1.612406\n",
            "Epoch de Treinamento : 3 [8000 / 60000] (13%) \t 1.545970\n",
            "Epoch de Treinamento : 3 [10000 / 60000] (17%) \t 1.593447\n",
            "Epoch de Treinamento : 3 [12000 / 60000] (20%) \t 1.550209\n",
            "Epoch de Treinamento : 3 [14000 / 60000] (23%) \t 1.557191\n",
            "Epoch de Treinamento : 3 [16000 / 60000] (27%) \t 1.596907\n",
            "Epoch de Treinamento : 3 [18000 / 60000] (30%) \t 1.574670\n",
            "Epoch de Treinamento : 3 [20000 / 60000] (33%) \t 1.563252\n",
            "Epoch de Treinamento : 3 [22000 / 60000] (37%) \t 1.575731\n",
            "Epoch de Treinamento : 3 [24000 / 60000] (40%) \t 1.532344\n",
            "Epoch de Treinamento : 3 [26000 / 60000] (43%) \t 1.566736\n",
            "Epoch de Treinamento : 3 [28000 / 60000] (47%) \t 1.527867\n",
            "Epoch de Treinamento : 3 [30000 / 60000] (50%) \t 1.542897\n",
            "Epoch de Treinamento : 3 [32000 / 60000] (53%) \t 1.549097\n",
            "Epoch de Treinamento : 3 [34000 / 60000] (57%) \t 1.556836\n",
            "Epoch de Treinamento : 3 [36000 / 60000] (60%) \t 1.575332\n",
            "Epoch de Treinamento : 3 [38000 / 60000] (63%) \t 1.553802\n",
            "Epoch de Treinamento : 3 [40000 / 60000] (67%) \t 1.553195\n",
            "Epoch de Treinamento : 3 [42000 / 60000] (70%) \t 1.571575\n",
            "Epoch de Treinamento : 3 [44000 / 60000] (73%) \t 1.571383\n",
            "Epoch de Treinamento : 3 [46000 / 60000] (77%) \t 1.536371\n",
            "Epoch de Treinamento : 3 [48000 / 60000] (80%) \t 1.572540\n",
            "Epoch de Treinamento : 3 [50000 / 60000] (83%) \t 1.532556\n",
            "Epoch de Treinamento : 3 [52000 / 60000] (87%) \t 1.550128\n",
            "Epoch de Treinamento : 3 [54000 / 60000] (90%) \t 1.532437\n",
            "Epoch de Treinamento : 3 [56000 / 60000] (93%) \t 1.597964\n",
            "Epoch de Treinamento : 3 [58000 / 60000] (97%) \t 1.535753\n",
            "Set de Teste: Perda Média0.0150: , Acurácia: 9561/10000 (96%\n",
            ")\n",
            "Epoch de Treinamento : 4 [0 / 60000] (0%) \t 1.568629\n",
            "Epoch de Treinamento : 4 [2000 / 60000] (3%) \t 1.588950\n",
            "Epoch de Treinamento : 4 [4000 / 60000] (7%) \t 1.566312\n",
            "Epoch de Treinamento : 4 [6000 / 60000] (10%) \t 1.541737\n",
            "Epoch de Treinamento : 4 [8000 / 60000] (13%) \t 1.596767\n",
            "Epoch de Treinamento : 4 [10000 / 60000] (17%) \t 1.556811\n",
            "Epoch de Treinamento : 4 [12000 / 60000] (20%) \t 1.552637\n",
            "Epoch de Treinamento : 4 [14000 / 60000] (23%) \t 1.579572\n",
            "Epoch de Treinamento : 4 [16000 / 60000] (27%) \t 1.506966\n",
            "Epoch de Treinamento : 4 [18000 / 60000] (30%) \t 1.571970\n",
            "Epoch de Treinamento : 4 [20000 / 60000] (33%) \t 1.599174\n",
            "Epoch de Treinamento : 4 [22000 / 60000] (37%) \t 1.526797\n",
            "Epoch de Treinamento : 4 [24000 / 60000] (40%) \t 1.528063\n",
            "Epoch de Treinamento : 4 [26000 / 60000] (43%) \t 1.591864\n",
            "Epoch de Treinamento : 4 [28000 / 60000] (47%) \t 1.549409\n",
            "Epoch de Treinamento : 4 [30000 / 60000] (50%) \t 1.533795\n",
            "Epoch de Treinamento : 4 [32000 / 60000] (53%) \t 1.561639\n",
            "Epoch de Treinamento : 4 [34000 / 60000] (57%) \t 1.530152\n",
            "Epoch de Treinamento : 4 [36000 / 60000] (60%) \t 1.568704\n",
            "Epoch de Treinamento : 4 [38000 / 60000] (63%) \t 1.560200\n",
            "Epoch de Treinamento : 4 [40000 / 60000] (67%) \t 1.548515\n",
            "Epoch de Treinamento : 4 [42000 / 60000] (70%) \t 1.535902\n",
            "Epoch de Treinamento : 4 [44000 / 60000] (73%) \t 1.561190\n",
            "Epoch de Treinamento : 4 [46000 / 60000] (77%) \t 1.586652\n",
            "Epoch de Treinamento : 4 [48000 / 60000] (80%) \t 1.593054\n",
            "Epoch de Treinamento : 4 [50000 / 60000] (83%) \t 1.584907\n",
            "Epoch de Treinamento : 4 [52000 / 60000] (87%) \t 1.534529\n",
            "Epoch de Treinamento : 4 [54000 / 60000] (90%) \t 1.580364\n",
            "Epoch de Treinamento : 4 [56000 / 60000] (93%) \t 1.523446\n",
            "Epoch de Treinamento : 4 [58000 / 60000] (97%) \t 1.565719\n",
            "Set de Teste: Perda Média0.0150: , Acurácia: 9618/10000 (96%\n",
            ")\n",
            "Epoch de Treinamento : 5 [0 / 60000] (0%) \t 1.548667\n",
            "Epoch de Treinamento : 5 [2000 / 60000] (3%) \t 1.530722\n",
            "Epoch de Treinamento : 5 [4000 / 60000] (7%) \t 1.552867\n",
            "Epoch de Treinamento : 5 [6000 / 60000] (10%) \t 1.557777\n",
            "Epoch de Treinamento : 5 [8000 / 60000] (13%) \t 1.565334\n",
            "Epoch de Treinamento : 5 [10000 / 60000] (17%) \t 1.534292\n",
            "Epoch de Treinamento : 5 [12000 / 60000] (20%) \t 1.501519\n",
            "Epoch de Treinamento : 5 [14000 / 60000] (23%) \t 1.561795\n",
            "Epoch de Treinamento : 5 [16000 / 60000] (27%) \t 1.550794\n",
            "Epoch de Treinamento : 5 [18000 / 60000] (30%) \t 1.524117\n",
            "Epoch de Treinamento : 5 [20000 / 60000] (33%) \t 1.554630\n",
            "Epoch de Treinamento : 5 [22000 / 60000] (37%) \t 1.525476\n",
            "Epoch de Treinamento : 5 [24000 / 60000] (40%) \t 1.551818\n",
            "Epoch de Treinamento : 5 [26000 / 60000] (43%) \t 1.515742\n",
            "Epoch de Treinamento : 5 [28000 / 60000] (47%) \t 1.548405\n",
            "Epoch de Treinamento : 5 [30000 / 60000] (50%) \t 1.502957\n",
            "Epoch de Treinamento : 5 [32000 / 60000] (53%) \t 1.616819\n",
            "Epoch de Treinamento : 5 [34000 / 60000] (57%) \t 1.510269\n",
            "Epoch de Treinamento : 5 [36000 / 60000] (60%) \t 1.513435\n",
            "Epoch de Treinamento : 5 [38000 / 60000] (63%) \t 1.545107\n",
            "Epoch de Treinamento : 5 [40000 / 60000] (67%) \t 1.556264\n",
            "Epoch de Treinamento : 5 [42000 / 60000] (70%) \t 1.578539\n",
            "Epoch de Treinamento : 5 [44000 / 60000] (73%) \t 1.572891\n",
            "Epoch de Treinamento : 5 [46000 / 60000] (77%) \t 1.513601\n",
            "Epoch de Treinamento : 5 [48000 / 60000] (80%) \t 1.539323\n",
            "Epoch de Treinamento : 5 [50000 / 60000] (83%) \t 1.512057\n",
            "Epoch de Treinamento : 5 [52000 / 60000] (87%) \t 1.533644\n",
            "Epoch de Treinamento : 5 [54000 / 60000] (90%) \t 1.566895\n",
            "Epoch de Treinamento : 5 [56000 / 60000] (93%) \t 1.596691\n",
            "Epoch de Treinamento : 5 [58000 / 60000] (97%) \t 1.557835\n",
            "Set de Teste: Perda Média0.0150: , Acurácia: 9656/10000 (97%\n",
            ")\n",
            "Epoch de Treinamento : 6 [0 / 60000] (0%) \t 1.553791\n",
            "Epoch de Treinamento : 6 [2000 / 60000] (3%) \t 1.560117\n",
            "Epoch de Treinamento : 6 [4000 / 60000] (7%) \t 1.543114\n",
            "Epoch de Treinamento : 6 [6000 / 60000] (10%) \t 1.548590\n",
            "Epoch de Treinamento : 6 [8000 / 60000] (13%) \t 1.522046\n",
            "Epoch de Treinamento : 6 [10000 / 60000] (17%) \t 1.566795\n",
            "Epoch de Treinamento : 6 [12000 / 60000] (20%) \t 1.538827\n",
            "Epoch de Treinamento : 6 [14000 / 60000] (23%) \t 1.514292\n",
            "Epoch de Treinamento : 6 [16000 / 60000] (27%) \t 1.569576\n",
            "Epoch de Treinamento : 6 [18000 / 60000] (30%) \t 1.520584\n",
            "Epoch de Treinamento : 6 [20000 / 60000] (33%) \t 1.578387\n",
            "Epoch de Treinamento : 6 [22000 / 60000] (37%) \t 1.527810\n",
            "Epoch de Treinamento : 6 [24000 / 60000] (40%) \t 1.514589\n",
            "Epoch de Treinamento : 6 [26000 / 60000] (43%) \t 1.516535\n",
            "Epoch de Treinamento : 6 [28000 / 60000] (47%) \t 1.546429\n",
            "Epoch de Treinamento : 6 [30000 / 60000] (50%) \t 1.560692\n",
            "Epoch de Treinamento : 6 [32000 / 60000] (53%) \t 1.518494\n",
            "Epoch de Treinamento : 6 [34000 / 60000] (57%) \t 1.532545\n",
            "Epoch de Treinamento : 6 [36000 / 60000] (60%) \t 1.521224\n",
            "Epoch de Treinamento : 6 [38000 / 60000] (63%) \t 1.535593\n",
            "Epoch de Treinamento : 6 [40000 / 60000] (67%) \t 1.611357\n",
            "Epoch de Treinamento : 6 [42000 / 60000] (70%) \t 1.513639\n",
            "Epoch de Treinamento : 6 [44000 / 60000] (73%) \t 1.523975\n",
            "Epoch de Treinamento : 6 [46000 / 60000] (77%) \t 1.547830\n",
            "Epoch de Treinamento : 6 [48000 / 60000] (80%) \t 1.506286\n",
            "Epoch de Treinamento : 6 [50000 / 60000] (83%) \t 1.547577\n",
            "Epoch de Treinamento : 6 [52000 / 60000] (87%) \t 1.544491\n",
            "Epoch de Treinamento : 6 [54000 / 60000] (90%) \t 1.561162\n",
            "Epoch de Treinamento : 6 [56000 / 60000] (93%) \t 1.549431\n",
            "Epoch de Treinamento : 6 [58000 / 60000] (97%) \t 1.503809\n",
            "Set de Teste: Perda Média0.0149: , Acurácia: 9693/10000 (97%\n",
            ")\n",
            "Epoch de Treinamento : 7 [0 / 60000] (0%) \t 1.555309\n",
            "Epoch de Treinamento : 7 [2000 / 60000] (3%) \t 1.532822\n",
            "Epoch de Treinamento : 7 [4000 / 60000] (7%) \t 1.543564\n",
            "Epoch de Treinamento : 7 [6000 / 60000] (10%) \t 1.515883\n",
            "Epoch de Treinamento : 7 [8000 / 60000] (13%) \t 1.577678\n",
            "Epoch de Treinamento : 7 [10000 / 60000] (17%) \t 1.549608\n",
            "Epoch de Treinamento : 7 [12000 / 60000] (20%) \t 1.507241\n",
            "Epoch de Treinamento : 7 [14000 / 60000] (23%) \t 1.522242\n",
            "Epoch de Treinamento : 7 [16000 / 60000] (27%) \t 1.542260\n",
            "Epoch de Treinamento : 7 [18000 / 60000] (30%) \t 1.524983\n",
            "Epoch de Treinamento : 7 [20000 / 60000] (33%) \t 1.511859\n",
            "Epoch de Treinamento : 7 [22000 / 60000] (37%) \t 1.501124\n",
            "Epoch de Treinamento : 7 [24000 / 60000] (40%) \t 1.576869\n",
            "Epoch de Treinamento : 7 [26000 / 60000] (43%) \t 1.580864\n",
            "Epoch de Treinamento : 7 [28000 / 60000] (47%) \t 1.531019\n",
            "Epoch de Treinamento : 7 [30000 / 60000] (50%) \t 1.529435\n",
            "Epoch de Treinamento : 7 [32000 / 60000] (53%) \t 1.556396\n",
            "Epoch de Treinamento : 7 [34000 / 60000] (57%) \t 1.500134\n",
            "Epoch de Treinamento : 7 [36000 / 60000] (60%) \t 1.547327\n",
            "Epoch de Treinamento : 7 [38000 / 60000] (63%) \t 1.527471\n",
            "Epoch de Treinamento : 7 [40000 / 60000] (67%) \t 1.582145\n",
            "Epoch de Treinamento : 7 [42000 / 60000] (70%) \t 1.563837\n",
            "Epoch de Treinamento : 7 [44000 / 60000] (73%) \t 1.536894\n",
            "Epoch de Treinamento : 7 [46000 / 60000] (77%) \t 1.547981\n",
            "Epoch de Treinamento : 7 [48000 / 60000] (80%) \t 1.496594\n",
            "Epoch de Treinamento : 7 [50000 / 60000] (83%) \t 1.521016\n",
            "Epoch de Treinamento : 7 [52000 / 60000] (87%) \t 1.505527\n",
            "Epoch de Treinamento : 7 [54000 / 60000] (90%) \t 1.470723\n",
            "Epoch de Treinamento : 7 [56000 / 60000] (93%) \t 1.483506\n",
            "Epoch de Treinamento : 7 [58000 / 60000] (97%) \t 1.558933\n",
            "Set de Teste: Perda Média0.0149: , Acurácia: 9674/10000 (97%\n",
            ")\n",
            "Epoch de Treinamento : 8 [0 / 60000] (0%) \t 1.496951\n",
            "Epoch de Treinamento : 8 [2000 / 60000] (3%) \t 1.531599\n",
            "Epoch de Treinamento : 8 [4000 / 60000] (7%) \t 1.562916\n",
            "Epoch de Treinamento : 8 [6000 / 60000] (10%) \t 1.518075\n",
            "Epoch de Treinamento : 8 [8000 / 60000] (13%) \t 1.511599\n",
            "Epoch de Treinamento : 8 [10000 / 60000] (17%) \t 1.557819\n",
            "Epoch de Treinamento : 8 [12000 / 60000] (20%) \t 1.523429\n",
            "Epoch de Treinamento : 8 [14000 / 60000] (23%) \t 1.519401\n",
            "Epoch de Treinamento : 8 [16000 / 60000] (27%) \t 1.521230\n",
            "Epoch de Treinamento : 8 [18000 / 60000] (30%) \t 1.515756\n",
            "Epoch de Treinamento : 8 [20000 / 60000] (33%) \t 1.521332\n",
            "Epoch de Treinamento : 8 [22000 / 60000] (37%) \t 1.560279\n",
            "Epoch de Treinamento : 8 [24000 / 60000] (40%) \t 1.519816\n",
            "Epoch de Treinamento : 8 [26000 / 60000] (43%) \t 1.541561\n",
            "Epoch de Treinamento : 8 [28000 / 60000] (47%) \t 1.483482\n",
            "Epoch de Treinamento : 8 [30000 / 60000] (50%) \t 1.494531\n",
            "Epoch de Treinamento : 8 [32000 / 60000] (53%) \t 1.554369\n",
            "Epoch de Treinamento : 8 [34000 / 60000] (57%) \t 1.583836\n",
            "Epoch de Treinamento : 8 [36000 / 60000] (60%) \t 1.564587\n",
            "Epoch de Treinamento : 8 [38000 / 60000] (63%) \t 1.552723\n",
            "Epoch de Treinamento : 8 [40000 / 60000] (67%) \t 1.487165\n",
            "Epoch de Treinamento : 8 [42000 / 60000] (70%) \t 1.512307\n",
            "Epoch de Treinamento : 8 [44000 / 60000] (73%) \t 1.539296\n",
            "Epoch de Treinamento : 8 [46000 / 60000] (77%) \t 1.513020\n",
            "Epoch de Treinamento : 8 [48000 / 60000] (80%) \t 1.519251\n",
            "Epoch de Treinamento : 8 [50000 / 60000] (83%) \t 1.581995\n",
            "Epoch de Treinamento : 8 [52000 / 60000] (87%) \t 1.534125\n",
            "Epoch de Treinamento : 8 [54000 / 60000] (90%) \t 1.515332\n",
            "Epoch de Treinamento : 8 [56000 / 60000] (93%) \t 1.562898\n",
            "Epoch de Treinamento : 8 [58000 / 60000] (97%) \t 1.531271\n",
            "Set de Teste: Perda Média0.0149: , Acurácia: 9717/10000 (97%\n",
            ")\n",
            "Epoch de Treinamento : 9 [0 / 60000] (0%) \t 1.513269\n",
            "Epoch de Treinamento : 9 [2000 / 60000] (3%) \t 1.500495\n",
            "Epoch de Treinamento : 9 [4000 / 60000] (7%) \t 1.551893\n",
            "Epoch de Treinamento : 9 [6000 / 60000] (10%) \t 1.494888\n",
            "Epoch de Treinamento : 9 [8000 / 60000] (13%) \t 1.500758\n",
            "Epoch de Treinamento : 9 [10000 / 60000] (17%) \t 1.543870\n",
            "Epoch de Treinamento : 9 [12000 / 60000] (20%) \t 1.525850\n",
            "Epoch de Treinamento : 9 [14000 / 60000] (23%) \t 1.521329\n",
            "Epoch de Treinamento : 9 [16000 / 60000] (27%) \t 1.503073\n",
            "Epoch de Treinamento : 9 [18000 / 60000] (30%) \t 1.526134\n",
            "Epoch de Treinamento : 9 [20000 / 60000] (33%) \t 1.504913\n",
            "Epoch de Treinamento : 9 [22000 / 60000] (37%) \t 1.555960\n",
            "Epoch de Treinamento : 9 [24000 / 60000] (40%) \t 1.528358\n",
            "Epoch de Treinamento : 9 [26000 / 60000] (43%) \t 1.501917\n",
            "Epoch de Treinamento : 9 [28000 / 60000] (47%) \t 1.530786\n",
            "Epoch de Treinamento : 9 [30000 / 60000] (50%) \t 1.511758\n",
            "Epoch de Treinamento : 9 [32000 / 60000] (53%) \t 1.533733\n",
            "Epoch de Treinamento : 9 [34000 / 60000] (57%) \t 1.515581\n",
            "Epoch de Treinamento : 9 [36000 / 60000] (60%) \t 1.495157\n",
            "Epoch de Treinamento : 9 [38000 / 60000] (63%) \t 1.524320\n",
            "Epoch de Treinamento : 9 [40000 / 60000] (67%) \t 1.491083\n",
            "Epoch de Treinamento : 9 [42000 / 60000] (70%) \t 1.489143\n",
            "Epoch de Treinamento : 9 [44000 / 60000] (73%) \t 1.501153\n",
            "Epoch de Treinamento : 9 [46000 / 60000] (77%) \t 1.530301\n",
            "Epoch de Treinamento : 9 [48000 / 60000] (80%) \t 1.552854\n",
            "Epoch de Treinamento : 9 [50000 / 60000] (83%) \t 1.539644\n",
            "Epoch de Treinamento : 9 [52000 / 60000] (87%) \t 1.522219\n",
            "Epoch de Treinamento : 9 [54000 / 60000] (90%) \t 1.532720\n",
            "Epoch de Treinamento : 9 [56000 / 60000] (93%) \t 1.542177\n",
            "Epoch de Treinamento : 9 [58000 / 60000] (97%) \t 1.510463\n",
            "Set de Teste: Perda Média0.0149: , Acurácia: 9740/10000 (97%\n",
            ")\n",
            "Epoch de Treinamento : 10 [0 / 60000] (0%) \t 1.503582\n",
            "Epoch de Treinamento : 10 [2000 / 60000] (3%) \t 1.530847\n",
            "Epoch de Treinamento : 10 [4000 / 60000] (7%) \t 1.521412\n",
            "Epoch de Treinamento : 10 [6000 / 60000] (10%) \t 1.506428\n",
            "Epoch de Treinamento : 10 [8000 / 60000] (13%) \t 1.502818\n",
            "Epoch de Treinamento : 10 [10000 / 60000] (17%) \t 1.472458\n",
            "Epoch de Treinamento : 10 [12000 / 60000] (20%) \t 1.552416\n",
            "Epoch de Treinamento : 10 [14000 / 60000] (23%) \t 1.507114\n",
            "Epoch de Treinamento : 10 [16000 / 60000] (27%) \t 1.502756\n",
            "Epoch de Treinamento : 10 [18000 / 60000] (30%) \t 1.541235\n",
            "Epoch de Treinamento : 10 [20000 / 60000] (33%) \t 1.552264\n",
            "Epoch de Treinamento : 10 [22000 / 60000] (37%) \t 1.493968\n",
            "Epoch de Treinamento : 10 [24000 / 60000] (40%) \t 1.494484\n",
            "Epoch de Treinamento : 10 [26000 / 60000] (43%) \t 1.519185\n",
            "Epoch de Treinamento : 10 [28000 / 60000] (47%) \t 1.477895\n",
            "Epoch de Treinamento : 10 [30000 / 60000] (50%) \t 1.520134\n",
            "Epoch de Treinamento : 10 [32000 / 60000] (53%) \t 1.505953\n",
            "Epoch de Treinamento : 10 [34000 / 60000] (57%) \t 1.511891\n",
            "Epoch de Treinamento : 10 [36000 / 60000] (60%) \t 1.553122\n",
            "Epoch de Treinamento : 10 [38000 / 60000] (63%) \t 1.525748\n",
            "Epoch de Treinamento : 10 [40000 / 60000] (67%) \t 1.500221\n",
            "Epoch de Treinamento : 10 [42000 / 60000] (70%) \t 1.511587\n",
            "Epoch de Treinamento : 10 [44000 / 60000] (73%) \t 1.532055\n",
            "Epoch de Treinamento : 10 [46000 / 60000] (77%) \t 1.576820\n",
            "Epoch de Treinamento : 10 [48000 / 60000] (80%) \t 1.506860\n",
            "Epoch de Treinamento : 10 [50000 / 60000] (83%) \t 1.522515\n",
            "Epoch de Treinamento : 10 [52000 / 60000] (87%) \t 1.549391\n",
            "Epoch de Treinamento : 10 [54000 / 60000] (90%) \t 1.558148\n",
            "Epoch de Treinamento : 10 [56000 / 60000] (93%) \t 1.537301\n",
            "Epoch de Treinamento : 10 [58000 / 60000] (97%) \t 1.503256\n",
            "Set de Teste: Perda Média0.0149: , Acurácia: 9746/10000 (97%\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  # Importa a biblioteca para visualização de gráficos\n",
        "\n",
        "# Colocando o modelo no modo de avaliação (avaliação desativa dropout e outras funções de treinamento)\n",
        "model.eval()\n",
        "\n",
        "# Vamos pegar um único exemplo de dados de teste, no caso, o índice 34 do conjunto de dados de teste\n",
        "data, target = dados_teste[34]  ## Pegamos um valor aleatório do Dataset de testes\n",
        "\n",
        "# Adiciona uma dimensão extra para compatibilizar com o formato esperado pelo modelo\n",
        "# Isso é necessário porque o modelo espera a entrada em forma de batch, mesmo que seja um único exemplo.\n",
        "data = data.unsqueeze(0).to(device)  # .to(device) garante que os dados sejam movidos para a GPU ou CPU conforme configurado\n",
        "\n",
        "# Passa a imagem através do modelo para fazer a predição\n",
        "output = model(data)  # O modelo realiza a predição para a imagem de entrada\n",
        "\n",
        "# Extrai a classe com a maior probabilidade de predição (predição do modelo)\n",
        "prediction = output.argmax(dim=1, keepdim=True).item()  # Obtém o índice da maior probabilidade\n",
        "\n",
        "# Imprime a predição para o usuário ver\n",
        "print(f\"prediction {prediction}\")  # Mostra o número que o modelo acha que é a imagem\n",
        "\n",
        "# Prepara a imagem para exibição: removemos a dimensão do batch e do canal (deixando apenas a imagem 28x28)\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()  # Convertendo para um array NumPy para usar com matplotlib\n",
        "\n",
        "# Exibe a imagem em escala de cinza\n",
        "plt.imshow(image, cmap='gray')  # Exibe a imagem em tons de cinza\n",
        "\n",
        "# Mostra a imagem na tela\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "N9O1BxIa2IWA",
        "outputId": "a19c3e86-7b9e-4221-e96e-7073286fed82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-f0309ddd8361>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NvsuaLkmtbry"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}